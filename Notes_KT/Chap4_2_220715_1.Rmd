https://github.com/tsunodak/cmbd-book/blob/master/chapter4/qlearning_groupdata.R#L44
ãŒå‚è€ƒã«ãªã‚‹
qlearning_groupdata.Rã‚’å‚è€ƒã«ã™ã‚‹

```{r}
# ----------------------------------------------------- #
# Qå­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚Šé¸æŠãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ï¼Œ
# ãã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ€å°¤æ¨å®šã‚’ã™ã‚‹ã€‚
# ----------------------------------------------------- #

# ãƒ¡ãƒ¢ãƒªï¼Œã‚°ãƒ©ãƒ•ã®ã‚¯ãƒªã‚¢
rm(list=ls())
graphics.off()

# æç”»ã®ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿
library(tidyverse)
library(gridExtra)
library(plotly)
# library(rgl)
# library(scatterplot3d)

# ä¹±æ•°ã®ã‚·ãƒ¼ãƒ‰ã®è¨­å®š 
set.seed(141)
```

```{r}
func_simu_qlearn <- function(T, alpha, beta, pr)
{
  # Q å€¤ã®åˆæœŸåŒ–( é¸æŠè‚¢ã®æ•°x T)
  Q <- matrix(numeric(2 * T), nrow = 2, ncol = T)
  
  c <- numeric(T)   # choice
  r <- numeric(T)   # reward
  pA <- numeric(T)  # choice probability
  
  
  
  for (t in 1:T) {
    # ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã§é¸æŠè‚¢A ã®é¸æŠç¢ºç‡ã‚’æ±ºå®šã™ã‚‹
    pA[t] <- 1 / (1 + exp(-beta * (Q[1, t] - Q[2, t])))
    
    if (runif(1, 0, 1) < pA[t]) {
      # 0~1ã®å®Ÿæ•°ã®ç”Ÿæˆã€€runif
      # å¼•æ•° n ã¯è©¦è¡Œã®å›æ•°ã€min ã¯å‡ºåŠ›ã™ã‚‹ä¹±æ•°ã®æœ€å°å€¤ã€max ã¯å‡ºåŠ›ã™ã‚‹ä¹±æ•°ã®æœ€å¤§å€¤ã§ã‚ã‚‹ã€‚
      
      # Aã‚’é¸æŠ
      c[t] <- 1
      r[t] <- as.numeric(runif(1, 0, 1) < pr[1]) # e.g.: 0.434 < 0.7ã®å ´åˆ
      # as.numericã§0 or 1ã«ã™ã‚‹
    } else {
      # Bã‚’é¸æŠ
      c[t] <- 2
      r[t] <- as.numeric(runif(1, 0, 1) < pr[2]) # e.g.: 0.434 < 0.3ã®å ´åˆ
    }
    
    # è¡Œå‹•ä¾¡å€¤ã®æ›´æ–°
    if (t < T) {
      Q[c[t], t + 1] <- Q[c[t], t] + alpha * (r[t] - Q[c[t], t])
      
      # é¸æŠè‚¢ã—ã¦ã„ãªã„è¡Œå‹•ã®ä¾¡å€¤ã¯ãã®ã¾ã¾ã®å€¤ã‚’æ¬¡ã®æ™‚åˆ»ã«å¼•ãç¶™ãã€‚
      # 3-c ã§c=1 ãªã‚‰2, c=2 ãªã‚‰1, ã¨ã„ã†ã‚ˆã†ã«
      # é€†å´ã®é¸æŠè‚¢ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒæ±‚ã¾ã‚‹ã€‚
      Q[3 - c[t], t + 1] <- Q[3 - c[t], t]
      
      # Qã®æ§‹é€ 
      # 1è¡Œç›®ã€€Aã®é¸æŠä¾¡å€¤
      # 2è¡Œç›®ã€€Bã®é¸æŠä¾¡å€¤
    }
  }
  
  NumA <- sum(c == 1)
  PercentA <- sum(c == 1) / T * 100
#  return(PercentA)
  return(list(Choice = c,Reward = r, ProbA = PercentA))
}

```
1äººåˆ†ã®ãƒ‡ãƒ¼ã‚¿ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
```{r}
T     <- 200     # è©¦è¡Œæ•°
alpha <- 0.3     # å­¦ç¿’ç‡
beta  <- 2.0      # é€†æ¸©åº¦
pr    <- c(0.7, 0.3) # ãã‚Œãã‚Œã®é¸æŠè‚¢ã®å ±é…¬ç¢ºç‡
Val   <- func_simu_qlearn(T, alpha, beta, pr)

print(Val)
print(sprintf("Percent of A choices: %.2f %%", Val$ProbA))
```
è¤‡æ•°äººåˆ†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
```{r}
# Initial values of subjects
T                     <- 200  # Numer of trials
N                     <- 30   # Number of subjects
initparam_alpha_all <- rnorm(N, mean=0.5, sd=0.1)
initparam_beta_all <- rnorm(N, mean=4,    sd=1)
initparam_alpha_all[initparam_alpha_all < 0.01] <- 0.01 # rnormã ã¨0~1ã«åã¾ã‚‰ãªã„å€¤ãŒç”Ÿæˆã•ã‚Œã‚‹å¯èƒ½æ€§ã‚
initparam_alpha_all[initparam_alpha_all > 0.99] <- 0.99
initparam_beta_all[initparam_beta_all   < 0.0]  <- 0.01
pr                    <- c(0.7, 0.3) # ãã‚Œãã‚Œã®é¸æŠè‚¢ã®å ±é…¬ç¢ºç‡
Rep                   <- 1

# Make simulation data

AllSub_choice <- matrix(, nrow = 0, ncol = T)
AllSub_reward <- matrix(, nrow = 0, ncol = T)

Ind_pA_all    <- as.numeric(length(initparam_alpha_all) * length(initparam_beta_all))
pA_all        <- numeric(Ind_pA_all)
sim_alpha_all <- numeric(length(initparam_alpha_all)*Rep) 
sim_beta_all  <- numeric(length(initparam_alpha_all)*Rep) 
sim_pA_all    <- numeric(length(initparam_alpha_all)*Rep) 
iRepLoop <- 1
for (iN in 1:N) {
  alpha_tmp  <- initparam_alpha_all[iN]
    beta_tmp <- initparam_beta_all[iN]
      Val    <- func_simu_qlearn(T, alpha_tmp, beta_tmp, pr)
      AllSub_choice <- rbind(AllSub_choice, Val$Choice)
      AllSub_reward <- rbind(AllSub_reward, Val$Reward)
      
      sim_alpha_all[iRepLoop] <- alpha_tmp
      sim_beta_all[iRepLoop]  <- beta_tmp
      sim_pA_all[iRepLoop]    <- as.numeric(Val$ProbA)
        
      iRepLoop <- iRepLoop + 1
}

# å„çµ„åˆã›æ¡ä»¶ã‚’ï¼‘ã¤ã®ãƒ©ãƒ™ãƒ«ã¨ãªã‚‹ã‚ˆã†ã«æ–°ãŸãªãƒ©ãƒ™ãƒ«ã‚’ä½œæˆã€€100æ¡ä»¶
Char_alpha <- as.character(sim_alpha_all)
Char_beta  <- as.character(sim_beta_all)
Char_param <- paste(Char_alpha , Char_beta , sep = "_") # 
# make dataframe
Data_sim   <- data.frame(sim_alpha_all, sim_beta_all, sim_pA_all, Char_param)
```
simulation dataã®æç”»
```{r}
summary(Data_sim)
# plot
hist(initparam_alpha_all)
hist(initparam_beta_all)
ggplot(Data_sim) +  geom_point(aes(x = sim_alpha_all, y= sim_pA_all, color = sim_beta_all))
plot_ly(x=~Data_sim$sim_alpha_all, y=~Data_sim$sim_beta_all, z=~Data_sim$sim_pA_all, color = sim_beta_all) # 3d plot
# z=~ã€€ãƒãƒ«ãƒ€ã‚’ã¤ã‘ã‚‹ã“ã¨ã§å¤‰æ•°åã‚’è¡¨ç¤ºã—ã¦ãã‚Œã‚‹
# Fig + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```
éšå±¤åŠ¹æœãƒ¢ãƒ‡ãƒ«
ã‚„ã‚‹ã“ã¨
ã¾ãšå›ºå®šåŠ¹æœåˆ†æã‚’è¡Œã† å®Ÿè£…ã—ã¦ã¿ã‚‹
æœ€å°¤æ¨å®šã‚’è¡Œã†ã€€qlearning_model_comparison_md.Rmdã‚’å‚è€ƒã«ã™ã‚‹
åŠåˆ†ç­”ãˆ~/cmbd-book-master/chapter4/qlearning_groupdata.Rã®L.259ãŒåŠåˆ†ç­”ãˆã«ãªã‚‹ğŸ’¦

```{r}
# A <- matrix(, nrow = 0, ncol = 200)
# str(A)
# str(AllSub_choice)
# rbind(AllSub_choice, Val$Choice)
# str(A)
```

```{r}
# æœ€å°¤æ¨å®šï¼ŒMAPæ¨å®šï¼Œæœ€é©åŒ–ã®ãŸã‚Rsolnpã‚’èª­ã¿è¾¼ã¿
library(Rsolnp)
# å›ºå®šåŠ¹æœã®Qå­¦ç¿’ãƒ¢ãƒ‡ãƒ«
func_qlearning_FE <- function(param, choice, reward)
{

  N <- dim(choice)[1]    # å‚åŠ è€…æ•°
  T <- dim(choice)[2]    # ä¸€å‚åŠ ã‚ãŸã‚Šã®è©¦è¡Œæ•°
  alpha <- param[1]
  beta <- param[2]
  c <- choice
  r <- reward
  
  # initialize log-likelihood
  ll <- 0
  
  for (idxsub in 1:N) {
    Q <- matrix(numeric(2*T), nrow=2, ncol=T)
    pA <- numeric(T) 
    
    for (t in 1:T) {
      
      pA[t] <- 1/(1+exp(-beta * (Q[1,t]-Q[2,t])))
      
      ll <- ll + (c[idxsub, t]==1) * log(pA[t]) +  (c[idxsub, t]==2) * log(1-pA[t])
      
      if (t < T) {
        
        Q[c[idxsub, t],t+1] <- Q[c[idxsub, t],t] + alpha * (r[idxsub, t] - Q[c[idxsub, t],t] ) 
        
        Q[3-c[idxsub, t],t+1] <- Q[3-c[idxsub, t],t]
      }
    }
  }
  return(-ll)
}

```

```{r}
# å›ºå®šåŠ¹æœ ML-------------------------------------------------------------
nParam = 2 # alpha, beta
fval <- Inf
for (idxopt in 1:10) {
  initparam <- runif(nParam, 0, 1.0) # nParam = 2;  0~1ã®æ•°ãŒ2å€‹å‡ºã¦ãã‚‹ã€‚alphaã¨Î²ã®åˆæœŸå€¤
  
  res <- solnp(
    initparam,
    fun = func_qlearning_FE,
    LB = c(0, 0), 
    UB = c(1, 20),
    control = list(trace = 0), #  https://www.rdocumentation.org/packages/Rsolnp/versions/1.16/topics/solnp
    choice = AllSub_choice,
    reward = AllSub_reward
  )
  # solnpã§ã‚ã‚Œã°ï¼ŒLB, UBã¨ã„ã†ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§æŒ‡å®šã§ãã¾ã™ã€‚ LB UB
  # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå­¦ç¿’ç‡ã¨é€†æ¸©åº¦ã®äºŒã¤ã§ã‚ã‚Šï¼Œãã‚Œãã‚Œå€¤ã®ç¯„å›²ã‚’[0,1], [0,20]ã«åˆ¶é™ã—ãŸã‘ã‚Œã°ï¼Œ ä»¥ä¸‹ã®ã‚ˆã†ã«ã—ã¾ã™ã€‚
  
  if (fval > res$values[length(res$values)]) {
    fval <- res$values[length(res$values)]
    paramest <- res$pars
  }
  
  FE_param <- list(paramest[1], paramest[2])
}
```

```{r}
print("Estimated Fixed-effect parameter alpha and Beta")
FE_param
```